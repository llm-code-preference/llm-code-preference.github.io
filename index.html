<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">

<head>
    <meta charset="utf-8">
    <!-- <meta name="description" content="Self-Refine is a framework for iteratively improving outputs from LLMs through a process of iterative creation with feedback"> -->
    <meta name="keywords" content="Code Preference, LLM4Code, Code LLM, ChatGPT, LLM, GPT4">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Learning Code Preference via Synthetic Evolution</title>
    <link rel="icon" type="image/x-icon" href="./asset/aws.ico">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.6.0/highlight.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@1.0.2/css/bulma.min.css">

    <script src="./static/js/index.js"></script>
    <script src="https://d3js.org/d3.v4.js"></script>

    <link href="https://cdn.jsdelivr.net/npm/prismjs@v1.x/themes/prism.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/prismjs@v1.x/components/prism-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@v1.x/plugins/autoloader/prism-autoloader.min.js"></script>


    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&display=swap"
        rel="stylesheet">
    <style>
        body {
            font-family: "Open Sans", sans-serif;
        }
    </style>


    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
</head>


<body>
    <nav class="navbar is-fixed-top is-transparent" role="navigation" aria-label="main navigation">
        <div class="navbar-menu">
            <div class="navbar-item has-dropdown is-hoverable">
                <a class="navbar-link">
                    Table of Content
                </a>
                <div class="navbar-dropdown has-text-centered">
                    <a class="navbar-item" href="#technique">
                        Technique: <span class="pal">CodeFavor</span>
                    </a>
                    <a class="navbar-item" href="#benchmark">
                        Benchmark: CodePrefBench
                    </a>
                    <a class="navbar-item" href="#quant-hpref">
                        Quantifying Human Preference
                    </a>
                    <a class="navbar-item" href="#controlled-experiment">
                        Controlled Experiments
                    </a>
                    <a class="navbar-item" href="#case-studies">
                        Case Studies
                    </a>
                    <a class="navbar-item" href="#citation">
                        Citation
                    </a>
                </div>
            </div>
        </div>
    </nav>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-large">
                            Learning Code Preference via Synthetic Evolution
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://jw-liu.xyz/">Jiawei Liu</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=HnkaCSQAAAAJ&hl=en">Thanh
                                    Nguyen</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=phbnAuIAAAAJ">Mingyue
                                    Shang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=nEuMO58AAAAJ">Hantian
                                    Ding</a><sup>2</sup>
                            </span>
                            <br>
                            <span class="author-block">
                                <a href="https://eelxpeng.github.io/">Xiaopeng Li</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.irisyuyu.com/">Yu Yu</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.amazon.science/author/varun-kumar">Varun Kumar</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://zijianwang.me/">Zijian Wang</a><sup>2</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup><i>
                                    <img src="asset/uiuc.png" width="12" />
                                    University of Illinois Urbana-Champaign</i></span>
                            <span class="center">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
                            <span class="author-block"><sup>2</sup><i>
                                    <img src="asset/aws.png" width="24" />
                                    AWS AI Labs</i></span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2410.03837"
                                        class="external-link button is-normal is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>

                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/amazon-science/llm-code-preference"
                                        class="external-link button is-normal is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>

                                <!-- Twitter Link. -->
                                <span class="link-block">
                                    <a href="https://x.com/JiaweiLiu_/status/1849873837178937369"
                                        class="external-link button is-normal is-dark">
                                        <span class="icon">
                                            <i class="fa-brands fa-twitter"></i>
                                        </span>
                                        <span>Tweet</span>
                                    </a>
                                </span>

                                <!-- Citation Link. -->
                                <!-- <span class="link-block">
                                    <a href="#citation" class="external-link button is-normal is-dark">
                                        <span class="icon">
                                            <i class="fas fa-link"></i>
                                        </span>
                                        <span>BibTeX</span>
                                    </a>
                                </span> -->

                                <!-- Dataset Link.
                                <span class="link-block">
                                    <a href="?" class="external-link button is-normal is-dark">
                                        <span class="icon">
                                            <i class="fas fa-database"></i>
                                        </span>
                                        <span>Data (TBA)</span>
                                    </a>
                                </span> -->
                            </div>
                        </div>

                        <div class="content has-text-justified is-size-5">
                            <center>
                                <div class="columns is-centered">
                                    <div class=" column is-three-quarters">
                                        <article>
                                            <div class="is-size-4 has-text-danger-75">
                                                <b>üôã <i>Quiz time! Try this out!</i> üìù</b>
                                            </div>
                                            <div class="message-header">
                                                <img id="example" src="./asset/correctness-even-odd-top.png" />
                                            </div>
                                            <button class="button is-info is-light toggle_button">
                                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                                                &nbsp;
                                                Click to show LLM & human responses
                                            </button>
                                            <div class="block toggle_content" style="display:none">
                                                <img id="example" src="./asset/correctness-even-odd-bot.png" />
                                                <caption>
                                                    <div class="is-size-5 has-text-danger-75">
                                                        <b>üéØ Code B is wrong: num=0 ‚Üí (0, 0) but 0 is also even
                                                        </b>
                                                    </div>
                                                    ü§Ø
                                                    <i>
                                                        If this takes some while & brain cells -- deciding code
                                                        preference is actually a challenging reasoning task (compared to
                                                        general
                                                        text styling preference). Prominent LLMs can also struggle with
                                                        it sometimes!
                                                    </i>
                                                    <hr>
                                                </caption>
                                            </div>
                                        </article>
                                    </div>
                                </div>
                            </center>

                            <br>
                            How to <i>effectively</i> & <i>efficiently</i> obtain <b>code preference</b> is crucial
                            to study! To this end, we present:
                            <ul>
                                <li><b>‚ú®Technique:</b> we introduce <span class="pal">CodeFavor</span>, an open recipe
                                    for training code preference models with synthetic code evolution such as code
                                    commits and code critiques.</li>
                                <li><b>‚ú®Benchmark:</b> we release <i>CodePrefBench</i> -- 1364 rigorously curated
                                    code preference tasks, covering verifiable objectives (‚úÖcorrectness,
                                    üöÄefficiency, üõ°Ô∏èsecurity) and üëçhuman preference.</li>
                                <li><b>‚ú®Findings:</b> (i) qualifying cost & performance of human preference based on 18
                                    developers; (ii) controlled experiments on data, code comments, criteria, & modeling
                                    in
                                    training code preference models; and (iii) case studies of LLM preference towards
                                    code
                                    correctness, efficiency, and security.</li>
                            </ul>
                        </div>


                        <div class="columns is-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="#technique" class="external-link button is-normal">
                                        <span>üîó Technique</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#benchmark" class="external-link button is-normal">
                                        <span>üîó Benchmark</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href=" #quant-hpref" class="external-link button is-normal">
                                        <span>üîó Quantifying Human Preference</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#controlled-experiments" class="external-link button is-normal">
                                        <span>üîó Controlled Experiments</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="#case-studies" class="external-link button is-normal">
                                        <span>üîó Case Studies</span>
                                    </a>
                                </span>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>

    <hr>

    <section class="hero" id="technique">
        <div class="hero-body is-size-5">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3 has-text-centered"><span class="pal">CodeFavor</span>: Code Evolution ‚Üí
                            Code Preference</h2>

                        <figure class="image is-64by64 has-text-centered">
                            <br>
                            <figure class="image">
                                <img src="./asset/overview.png">
                            </figure>
                            <caption>
                                <i>
                                    <span class="pal">CodeFavor</span> is a framework that trains pairwise preference
                                    models with synthetic code preferences generated from code evolution like
                                    code commits and code critiques.
                                </i>
                            </caption>
                            <br>
                        </figure>

                        <br>
                        <div class="columns">
                            <div class="column has-text-justified">
                                <h3 class="title is-4">Preference Modeling</h3>

                                <span class="pal">CodeFavor</span> trains code preference models that predict
                                pairwise preference using the following input formats:

                                <ol>
                                    <li>
                                        <b>Instruction:</b> The instruction associated with the code candidates.
                                    </li>
                                    <li>
                                        <b>Code pair:</b> A pair of code snippet candidates to be compared.
                                    </li>
                                    <li>
                                        <b>Criteria:</b> The criteria for comparison, such as correctness and
                                        efficiency.
                                    </li>
                                </ol>

                                <br>
                                Based on this format, the preference model is trained to predict code preference using
                                two modeling methods:

                                <ol>
                                    <li>
                                        <b>Classification:</b> the preference is decided by the decoding probability of
                                        next single tokens such as "A" or "B" (following <a
                                            href="https://arxiv.org/pdf/2305.10425">SLiC-HF</a>).
                                    </li>
                                    <li>
                                        <b>Generation:</b> the preference is decided by the generation of analysis and
                                        conclusion over the code pair.
                                    </li>
                                </ol>

                                <br>
                                <article class="message has-text-text-40 is-light is-size-5">
                                    <div class="message-header">
                                        <p>üí° Design considerations</p>
                                        <button class="button toggle_button">
                                            <i class="fas fa-angle-down" aria-hidden="true"></i>
                                        </button>
                                    </div>
                                    <div class="block toggle_content" style="display:none">
                                        <div class="column is-size-6">
                                            <ul>
                                                <li>
                                                    <b>Criteria:</b> code preference requires explicit, fine-grained
                                                    declaration of criteria (following
                                                    <a href="https://arxiv.org/abs/2310.08491">Prometheus</a>) to
                                                    make code preferences more decidable.
                                                </li>
                                                <li>
                                                    <b>Classification:</b> the classification modeling provides the
                                                    advantage of efficiency in training and inference. Additionally,
                                                    while training over synthetic data might introduce noisy
                                                    internal reasoning traces (esp. for harder tasks), learning to
                                                    directly classify the preference can avoid the impact of confusing
                                                    traces.
                                                </li>
                                                <li>
                                                    <b>Generation:</b> just like LLM-as-a-Judge, generation modeling
                                                    provides better interpretability when the preference decision is
                                                    obscure. Meanwhile, generation modeling is more natural when
                                                    training a preference model based on a trained model.
                                                </li>
                                            </ul>
                                        </div>
                                    </div>
                                </article>

                                <br><br>
                                <h3 class="title is-4">Synthetic Data Generation</h3>
                                <ul>
                                    <li><b>Code commits (Commit-Instruct):</b>
                                        <span class="pal">CodeFavor</span> transforms a given code commit into a
                                        synthetic code preference training sample. Specifically, it employs a critic
                                        model to rephrase the pre-commit code to a <i>rejected</i> code candidate and
                                        the post-commit code to the <i>accepted</i> code candidate. Code quality
                                        filtering is further applied to ensure the quality of the preference samples.
                                    </li>
                                    <br>
                                    <li><b>Code critiques (Critic-Evol):</b>
                                        Given an code instruction, <span class="pal">CodeFavor</span> first lets a
                                        smaller model generate a draft code candidate. A larger critic model is then
                                        used to check its code quality and provide feedback. If the draft code is
                                        considered improveable, the critic model will provide a revised code candidate,
                                        combining both we obtain a contrastive code pair for training the preference
                                        model.
                                    </li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <hr>
    <section class="hero" id="benchmark">

        <div class="hero-body is-size-5">
            <div class="container is-max-desktop">
                <div class="columns is-centered ">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3 has-text-centered">CodePrefBench: Evaluating Code Preferences</h2>

                        <figure class="image is-64by64 has-text-centered">
                            <br>
                            <img src="asset/cpb-overview.png">
                            <caption>
                                <i>
                                    Overview of CodePreferenceBench.
                                </i>
                            </caption>
                            <br>
                        </figure>

                        <br>
                        <article class="message is-light is-link is-size-5">
                            <div class="message-body">
                                <span class="icon">
                                    <i class="fab fa-github"></i>
                                </span> Instructions to run CodePreferenceBench is available <a
                                    href="https://github.com/amazon-science/llm-code-preference?tab=readme-ov-file#-evaluation">
                                    here</a>!
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header">
                                <p>üí° Sample task</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <img id="example" src="./asset/correctness-even-odd.png" />
                            </div>
                        </article>

                        <br>
                        <h2 class="title is-4">Setup</h2>

                        <b>Code preference can never be evaluated from just one angle!</b>
                        Therefore, we adapt a comprehensive set of objectives (encoded by the criteria field) to
                        evaluate the code preferences of both LLMs and human developers:

                        <ol>
                            <li><b>‚úÖ Code correctness:</b>
                                the ground-truth label is determined by exercising code candiates over
                                massive
                                <a href="https://github.com/evalplus/evalplus">EvalPlus</a> test cases.
                            </li>
                            <li><b>üöÄ Code efficiency:</b>
                                labels are obtained by profiling the # of CPU instructions of code
                                candidates over performan-exercising tasks and test inputs in <a
                                    href="https://www.arxiv.org/abs/2408.06450">EvalPerf</a>.
                            </li>
                            <li><b>üõ°Ô∏è Code security:</b>
                                each task includes a pair of secure and vulnerable code snippets, whose
                                security
                                is
                                exaimined by static analyzers in <a
                                    href="https://github.com/meta-llama/PurpleLlama/tree/main/CybersecurityBenchmarks">CyberSecEval</a>.
                            </li>
                            <li><b>üëç Human preference:</b>
                                we engage 18 developers, with 3 annotator per code pair.
                                The code candidates are sampled from LLMs and are paired using the maximum
                                edit distance to ensure sufficient differentiation.
                                Detailed annotation statistics are available in the <a href="#quant-hpref">Quantifying
                                    Human Preference</a> section.
                            </li>
                        </ol>

                        <br>
                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header">
                                <p>‚öôÔ∏è Examinee setup</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    <ul>
                                        <li><b>Generative models:</b>
                                            are prompt to generate conclusions like "Code A is better than Code B" using
                                            greedy decoding.
                                        </li>
                                        <li><b>Classification models:</b>
                                            decide their preference based on the decoding probability of the next token
                                            of "A" and "B".
                                        </li>
                                        <li><b>Human baseline:</b> is conducted by having three developers for
                                            each task via major voting.
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </article>


                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header">
                                <p>üì¶ <span class="pal">CodeFavor</span> data</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    <ul>
                                        <li><b>üì¶ Commit-Instruct-EditPack:</b> 20.6k code preference samples
                                            synthesized using permissive code commits from <a
                                                href="https://huggingface.co/datasets/nuprl/EditPackFT">EditPackFT</a>
                                            (22.4k permissive Python commits).
                                            We use Llama-3-70B-Instruct as the critic model.
                                        </li>
                                        <li><b>üì¶ Critic-Evol-SOSS:</b> 41.6k code preference samples.
                                            We run Llama-3-8B-Instruct as the draft model over 50.6k coding
                                            instructions from the <a
                                                href="https://huggingface.co/datasets/bigcode/self-oss-instruct-sc2-exec-filter-50k">
                                                Self-OSS-Instruct dataset
                                            </a> to produce draft code responses.
                                            We then use Llama-3-70B-Instruct as the critic model to provide feedback and
                                            generate the revised code, after filtering out 17.9% of "good enough"
                                            drafts.
                                        </li>
                                        <li><b>üî® Post-processing:</b>
                                            To mitigate positional bias, we augment the dataset by flipping the order
                                            within each
                                            code pair, which also doubles the training samples. Besides, we clip the
                                            code comments in Critic-Evol
                                            samples, given that comments barely affect code quality metrics and
                                            LLM-generated comments may
                                            let faulty code "sound right".
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </article>

                        <br><br>
                        <h2 class="title is-4">Main Results</h2>

                        <figure class="image is-64by64" id="fig-main-results">
                            <br>
                            <figure class="image">
                                <img src="./asset/main-eval.png">
                            </figure>
                            <caption><i>Accuracy (%) of evaluated models on CodePrefBench.
                                    Scores within 1pp of the highest are highlighted in bold.
                                    Bracketed numbers denote the ranges of uncertain responses,
                                    half of whose ratio is accounted for the final accuracy score.</i></caption>
                            <br>
                        </figure>
                    </div>
                </div>
            </div>
    </section>


    <hr>
    <section class="hero" id="quant-hpref">
        <div class="hero-body is-size-5">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3 has-text-centered">Quantifying Human Preference</h2>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header">
                                <p>‚öôÔ∏è Human baseline setup</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    We engage <b>18 developers</b> (95% contractors have 2+ YOE in programming) to
                                    provide code preference labels for both (i) creating human-preference benchmark; and
                                    (ii) serving as human baseline. This section focuses on (ii) -- to quantify the
                                    performance of human preference in assessing the verifiable properties of code.
                                </div>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                <p>üîç Human preference strongly aligns with <span
                                        style="background-color: greenyellow;">code correctness</span>, but can struggle
                                    with <span style="background-color: lightpink;">non-functional
                                        properties</span>.
                                </p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:block">
                                <div class="column is-size-6">
                                    The <a href="#fig-main-results">result figure</a> presents the accuracy
                                    of human preference via 3-developer major voting:

                                    <ul>
                                        <li><b>‚úÖ Correctness:</b> human preference <b>best</b> aligns with code
                                            correctness, which is also the most challenging category for LLMs.
                                        </li>
                                        <li><b>üöÄ Efficiency:</b> human preference can be suboptimal to the best LLMs.
                                        </li>
                                        <li><b>üõ°Ô∏è Security:</b> human preference is unsure for a
                                            significant portion (73.9%) of code security pairs.
                                        </li>
                                    </ul>

                                </div>
                            </div>
                        </article>


                        <h2 class="title is-4">Confidence</h2>
                        <div class="columns is-max-desktop is-centered">
                            <div class="column is-size-6">
                                Developers are overall confident with their annotations, esp. for code correctness,
                                whose confidence level is higher than that for efficiency and
                                security, corresponding to the accuracy results.
                                Notes show that it's partially because correctness can be assessed by manual
                                testing, while others are less straightforward to evaluate.
                            </div>
                            <div class="column has-text-centered">
                                <img src="asset/confidence.png">
                                <caption><i>
                                        Human confidence for different objectives</i>
                                </caption>
                            </div>
                        </div>

                        <h2 class="title is-4">Time</h2>
                        <div class="columns is-max-desktop is-centered">
                            <div class="column is-size-6">
                                <ol>
                                    <li><b>Labeling human pref. is time-consuming:</b> after removing
                                        top-1%-longest outliers, each task can cost each developer <b>7.8 minutes on
                                            average</b>, with the 99-percentile of 26 minutes.
                                        This is expected as code can be much harder to understand than general
                                        natural language.
                                    </li>
                                    <li><b>The code correctness category is faster</b>/easier to label than that of
                                        efficiency
                                        and security, corresponding to the accuracy results and confidence levels.
                                    </li>
                                </ol>
                            </div>
                            <div class="column has-text-centered">
                                <img src="asset/label-time.png">
                                <caption><i><a
                                            href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a>
                                        of labeling time (top-left is faster)</i></caption>
                            </div>
                        </div>

                        <h2 class="title is-4">Cost</h2>
                        <div class="columns is-max-desktop is-centered">
                            <div class="column is-size-6">
                                <b>Human preference can be higly costly:</b>
                                it can be two orders of magnitude more expensive than serving one of the largest
                                open-weight LLMs. Yet, the overall accuracy of human preference is not as competitive as
                                that for such large models (mainly due to the huge gap in judging code security).
                            </div>
                            <div class="column has-text-centered">
                                <img src="asset/cost.png">
                                <caption><i>Estimated per-sample cost and accuracy</i></caption>
                            </div>
                        </div>

                        <h2 class="title is-4">Implications and Open Questions</h2>
                        <article class="message is-light">
                            <div class="message-body">
                                Human preference strongly aligns with code correctness, but can struggle with
                                non-functional properties -- <b>shall we focus on using human preference for
                                    selecting functional code and leave non-functional properties to LLMs or
                                    external tools?</b>
                            </div>
                        </article>

                        <article class="message is-light">
                            <div class="message-body">
                                Labeling human preference for code is expensive and time-consuming -- <b>how can we
                                    improve the productivity of human preference for more cost-effective and faster
                                    preference annotation?</b>
                            </div>
                        </article>

                        <article class="message is-light">
                            <div class="message-body">
                                Code is much harder to understand than general natural language -- even code
                                preferences from experienced developers can be imperfect -- <b>how can we assure the
                                    quality of openly crowd-sourced preference votes for code?</b>
                            </div>
                        </article>

                    </div>
                </div>
            </div>
        </div>
    </section>


    <hr>
    <section class="hero" id="controlled-experiments">
        <div class="hero-body is-size-5">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3 has-text-centered">Controlled Experiments</h2>

                        We compile a list of empirical conclusions based on our controlled experiments:
                        <br><br>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                üîç Model merging outperforms data mixture by ~5%.
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:block">
                                <div class="column is-size-6">
                                    We have two sources of datasets: <b>Commit-Instruct-EditPack</b> and
                                    <b>Critic-Evol-SOSS</b>. To make use of both datasets, we tried two strategies:
                                    (i) <b>data mixture</b> -- directly mix the two datasets; and (ii) <b>model
                                        merging</b>
                                    -- train two models separately and merge them in the inference stage. The result
                                    indicates that model merging can lightly surpass data mixture by ~5% in overall
                                    accuracy.
                                </div>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                üîç Classification v.s. generation: tradeoffs
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    <ul>
                                        <li><b>Classification</b> is <b>fast by design</b> and often leads to more
                                            accurate
                                            preference for <b>code correctness</b>.
                                        </li>
                                        </li>
                                        <li><b>Generation</b> tends to bring <b>holistic improvements</b>, leading to a
                                            higher overall score.
                                        </li>
                                    </ul>
                                </div>
                            </div>
                        </article>


                        <figure class="image is-64by64 has-text-centered">
                            <br>
                            <img src="asset/control-exp-data.png">
                            <caption><i>
                                    Impact of training <b>data and modeling</b> in training <span
                                        class="pal">CodeFavor</span> models.</i>
                            </caption>
                            <br>
                        </figure>


                        <br>
                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                üîç Detailing criteria leads to more accurate preference
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    Removing the criteria field or using a generalist criterion can lead to performance
                                    degradation.
                                </div>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                üîç Code comments can be distracting
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    By default, we strip the code comments of code candidates in both training and
                                    inference. Our ablation study shows that <b>using code comments in either training
                                        or inference can overall lead to less accurate preference</b>.
                                    This is likely due to the self-bias of LLM-generated comments which can bring false
                                    confidence in code preference prediciton.
                                </div>
                            </div>
                        </article>


                        <figure class="image is-64by64 has-text-centered">
                            <br>
                            <img src="asset/control-exp-input.png">
                            <caption>
                                <i>
                                    Controlled experiments on <b>input prompts</b>.
                                </i>
                            </caption>
                            <br>
                        </figure>

                        <br>
                        <article class="message has-text-text-40 is-light is-size-5">
                            <div class="message-header has-text-centered">
                                üîç Critic-Evol: can we use equally strong draft and critic models?
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <div class="column is-size-6">
                                    Our controlled experiments shows that using the same model for drafting and revising
                                    in Critic-Evol can lead to <b>performance drops</b>. Additionally, we observe
                                    <b>self-bias
                                        again</b>:
                                    using the same model leads to a higher filtering rate --
                                    note a sample is only filtered when the critic model thinks the draft is "good
                                    enough".
                                </div>
                                <figure class="image is-64by64 has-text-centered">
                                    <img src="asset/control-exp-modelgen.png">
                                    <caption>
                                        <i>
                                            Impact of <b>draft and critic models</b> in training with Critic-Evol.
                                        </i>
                                    </caption>
                                </figure>
                            </div>
                        </article>

                    </div>
                </div>
            </div>
    </section>


    <hr>
    <section class="hero" id="case-studies">
        <div class="hero-body is-size-5">
            <div class="container is-max-desktop">
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Case Studies</h2>
                        <span class="subtitle is-5 is-italic">Examples of CodePrefBench tasks and responses from LLMs
                            and human developers.</span>
                        <br><br>


                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>‚úÖ Human baseline misses requirement details in the instruction.</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:block">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/correctness-split.png">
                                    <caption>
                                        <i>All models capture the ‚Äúlower-case‚Äù requirement, while all human annotators
                                            miss this detail in the description and choose Code A (likely due to its
                                            simplicity).</i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>‚úÖ Reasoning mistakes in Claude 3.5 Sonnet and DeepSeek V2.5</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/correctness-pali.png">
                                    <caption>
                                        <i>Both Claude 3.5 Sonnet and DeepSeek V2.5 yield false claims due to their
                                            broken reasonings. Our <span class="pal">CodeFavor</span> classification
                                            model also predicts false conclusion. Yet, the three annotators as the human
                                            baseline consistently and correctly select the right code.</i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>


                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>üöÄ Algorithmic complexity analysis is important!
                                </p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/effi-divisor.png">
                                    <caption>
                                        <i>While Claude 3.5 Sonnet is aware of the better O(‚àön) complexity of CODE A,
                                            Mistral Large 2 misses the algorithmic analysis and favors CODE B for being
                                            "straightforward".
                                        </i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>üöÄ Don't under weigh the efficiency significance of built-in functions!</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/effi-number.png">
                                    <caption>
                                        <i>
                                            Code A is efficient for using the built-in function
                                            <code>str.count()</code>, while Code B's efficiency is demonstrated by a
                                            single-pass implementation (constant optimization).
                                            Using built-in functions has a much bigger significance here as
                                            <code>str.count()</code>
                                            is implemented not only in native C but also using <a
                                                href="https://web.archive.org/web/20201107074620/http://effbot.org/zone/stringlib.htm">extensively
                                                optimized
                                                algorithms</a>.
                                            Here, DeepSeek V2.5 under-weighs the significance of
                                            <code>str.count()</code> compared to a single-pass implementation at the
                                            same algorithmic complexity
                                        </i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>üõ°Ô∏è <code>os.popen</code> or <code>subprocess.run</code>? Human baseline predicts
                                    false security preference.</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/sec-cmd.png">
                                    <caption>
                                        <i>Both Claude 3.5 Sonnet and the <span class="pal">CodeFavor</span> model
                                            choose the right side (Code
                                            B), as <code>subprocess.run</code> is generally safe to command injection.
                                            Nonetheless, Gemini 1.5 Pro concludes with a tied preference as it
                                            thinks both code can be command-injected, which is not true but might come
                                            by design due to some security consideration. Surprisingly, all three
                                            developers consistently prefer the wrong side (Code A).</i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>

                        <article class="message has-text-text-40 is-light">
                            <div class="message-header">
                                <p>üõ°Ô∏è <code>SHA-256</code> or <code>SHA-1</code> encryption? Defensive
                                    code security preference in Gemini.</p>
                                <button class="button toggle_button">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </button>
                            </div>
                            <div class="block toggle_content" style="display:none">
                                <figure class="image is-64by64 has-text-centered">
                                    <br>
                                    <img src="asset/sec-sha.png">
                                    <caption>
                                        <i>While most models choose the right side as they know that SHA-256 is a more
                                            secure version of SHA-1, Gemini 1.5 Pro fails to mention this point
                                            and leads to a tied conclusion. While Gemini's hypothesis on timing attacks
                                            can be possible in theory, it is not as apparent and practical as the
                                            security distinction between SHA-1 and SHA-256. Nonetheless, this can come
                                            from a security consideration to avoid Gemini Pro being used in
                                            cyber-security tasks.</i>
                                    </caption>
                                    <br>
                                </figure>
                            </div>
                        </article>

    </section>





    <hr>

    <section class="section" id="citation">
        <div class="container is-max-desktop content">
            <h2 class="title is-3 has-text-centered">Citation</h2>

            <div class="is-size-5">
                <pre><code>@article{liu2024learning,
    title = {Learning Code Preference via Synthetic Evolution},
    author = {Liu, Jiawei and Nguyen, Thanh and Shang, Mingyue and Ding, Hantian and Li, Xiaopeng and Yu, Yu and Kumar, Varun and Wang, Zijian},
    journal = {arXiv preprint arXiv:2410.03837},
    year = {2024},
}</code></pre>
            </div>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <!-- back to top -->
            <div class="content has-text-centered">
                <span class="link-block">
                    <a href="#top" class="external-link button is-normal is-dark">
                        <span class="icon">
                            <i class="fas fa-arrow-up"></i>
                        </span>
                        <span>Back to Top</span>
                    </a>
                </span>
                <br><br>
                <div class="content">
                    <p>
                        The template is adapted from <a href="https://selfrefine.info/">Self-Refine</a>.
                        <br>ü§ó Feel free to reuse ours with proper attribution.
                    </p>
                </div>
            </div>
        </div>
    </footer>

</body>


</html>